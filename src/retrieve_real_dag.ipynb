{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__class__\n",
      "__delattr__\n",
      "__dict__\n",
      "__dir__\n",
      "__doc__\n",
      "__eq__\n",
      "__format__\n",
      "__ge__\n",
      "__getattribute__\n",
      "__gt__\n",
      "__hash__\n",
      "__init__\n",
      "__init_subclass__\n",
      "__le__\n",
      "__lt__\n",
      "__module__\n",
      "__ne__\n",
      "__new__\n",
      "__reduce__\n",
      "__reduce_ex__\n",
      "__repr__\n",
      "__setattr__\n",
      "__sizeof__\n",
      "__str__\n",
      "__subclasshook__\n",
      "__weakref__\n",
      "adj_mat\n",
      "all_vi\n",
      "class_varname\n",
      "dag\n",
      "feature_varnames\n",
      "label_features\n",
      "label_y\n",
      "labels\n",
      "merge_dat\n",
      "test_dataset\n",
      "test_features\n",
      "test_y\n",
      "train_label_dataset\n",
      "train_unlabel_dataset\n",
      "unlabel_features\n",
      "unlabel_y\n",
      "val_dataset\n",
      "val_features\n",
      "val_y\n",
      "vertex_dict\n",
      "pausing here\n",
      "pausing here\n",
      "pausing here\n",
      "cause idx\n",
      "[0, 20, 14, 7]\n",
      "effect idx\n",
      "[1, 5, 8, 9, 12, 15, 16, 19]\n"
     ]
    }
   ],
   "source": [
    "#breastcancer...\n",
    "\n",
    "from benchmarks_CGAN_SUPERVISED_CLASSIFIER import *\n",
    "\n",
    "\n",
    "\n",
    "pkl_n='/media/krillman/240GB_DATA/codes2/SSL_GCM/data/dataset_real_bcancer_diagnosis_zscore/d_n_real_bcancer_diagnosis_zscore_s_i_0_dataset_class.pickle'\n",
    "\n",
    "#pkl_candidate=glob.glob(pkl_dn)\n",
    "\n",
    "\n",
    "with open(pkl_n, 'rb') as f:\n",
    "    dsc = pickle.load(f)\n",
    "    \n",
    "    \n",
    "    for d in dir(dsc):\n",
    "        print(d)\n",
    "    \n",
    "    \n",
    "dsc_generators=OrderedDict() #ordered dict of the generators\n",
    "dsc.label_var=dsc.class_varname\n",
    "label_name = dsc.label_var\n",
    "\n",
    "ordered_keys=[dsc.labels[v] for v in order_to_train]\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "order_to_train=dsc.dag.topological_sorting()\n",
    "dsc_generators=OrderedDict() #ordered dict of the generators\n",
    "label_name = dsc.class_varname\n",
    "ordered_keys=[dsc.labels[v] for v in order_to_train]\n",
    "\n",
    "\n",
    "is_lab=[k==label_name for k in ordered_keys]\n",
    "\n",
    "\n",
    "lab_transform = lambda lab: 'label' if lab else 'feature'\n",
    "feat_or_lab = [lab_transform(c) for c in is_lab]\n",
    "\n",
    "dsc.variable_types = feat_or_lab\n",
    "\n",
    "dsc.variable_types\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if type(label_name)=='list':\n",
    "    ln=label_name[0]\n",
    "    label_idx = np.where(np.array(ordered_keys) == ln)[0][0]\n",
    "else:\n",
    "    label_idx = np.where(np.array(ordered_keys) == label_name)[0][0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "unlabelled_keys = ordered_keys[:label_idx]\n",
    "labelled_key = ordered_keys[label_idx]\n",
    "conditional_keys = ordered_keys[label_idx + 1:]\n",
    "\n",
    "\n",
    "#split into parent, spouse, child\n",
    "topsort_order = np.array(dsc.variable_types)\n",
    "\n",
    "print('pausing here')\n",
    "\n",
    "lab_idx = np.where(topsort_order == 'label')[0]\n",
    "\n",
    "\n",
    "def reduce_list(in_list):\n",
    "    return (sum(in_list, []))\n",
    "\n",
    "\n",
    "def return_mb_dict(dag):\n",
    "\n",
    "    mb_dict = {}  # getting markov blanket\n",
    "    for n in dag.nodes:\n",
    "        mb_dict[n] = {}\n",
    "        # get parents\n",
    "        mb_dict[n]['parent'] = [n for n in dag.predecessors(n)]\n",
    "        # get children\n",
    "        mb_dict[n]['children'] = [n for n in dag.successors(n)]\n",
    "        # spouses\n",
    "        mb_dict[n]['spouses'] = reduce_list([[s for s in dag.predecessors(c)] for c in mb_dict[n]['children']])\n",
    "\n",
    "    return(mb_dict)\n",
    "\n",
    "\n",
    "# need to partition into spouse also\n",
    "\n",
    "networkx_dag = dsc.dag.to_networkx()  # converting to networkx object for easier\n",
    "mb_dict = return_mb_dict(networkx_dag)\n",
    "mb_label_var = mb_dict[lab_idx[0]]\n",
    "\n",
    "\n",
    "\n",
    "#convert to unique elements\n",
    "\n",
    "#then remove variables shared bw parent&spouse to just parent\n",
    "\n",
    "for k in mb_label_var.keys():\n",
    "    mb_label_var[k]=list(set(mb_label_var[k]))\n",
    "\n",
    "# ok now if any v common to spouse/children, put in effect only\n",
    "\n",
    "for v in mb_label_var['children']:\n",
    "    if v in mb_label_var['spouses']:\n",
    "        mb_label_var['spouses'].remove(v)\n",
    "\n",
    "# ok now if any v common to spouse/parent, put in parent only\n",
    "for v in mb_label_var['parent']:\n",
    "    if v in mb_label_var['spouses']:\n",
    "        mb_label_var['spouses'].remove(v)\n",
    "\n",
    "\n",
    "print('pausing here')\n",
    "# remove self from spouses\n",
    "try:\n",
    "    mb_label_var['spouses'].remove(lab_idx[0])\n",
    "except:\n",
    "    next\n",
    "finally:\n",
    "    next\n",
    "\n",
    "\n",
    "\n",
    "# partition into causal/label/effect index\n",
    "ce_dict = {'cause': list(set(mb_label_var['parent'])),\n",
    "                'spouse': list(set(mb_label_var['spouses'])),\n",
    "                'lab': lab_idx[0],\n",
    "                'effect': list(set(mb_label_var['children']))}\n",
    "\n",
    "print('pausing here')\n",
    "\n",
    "\n",
    "unlabelled_keys = ordered_keys[:label_idx]\n",
    "labelled_key = ordered_keys[label_idx]\n",
    "conditional_keys = ordered_keys[label_idx + 1:]\n",
    "\n",
    "\n",
    "cause_idx=ce_dict['cause']\n",
    "\n",
    "effect_idx=ce_dict['effect']\n",
    "\n",
    "#subtract 1 for any over 18...\n",
    "\n",
    "def subtract_over_lab_idx(features,lab_idx):\n",
    "    newfeats=[]\n",
    "    for f in features:\n",
    "        if f>lab_idx:\n",
    "            f=f-1\n",
    "        newfeats.append(f)\n",
    "        \n",
    "    return(newfeats)\n",
    "\n",
    "cause_idx=subtract_over_lab_idx(cause_idx,lab_idx[0])\n",
    "effect_idx=subtract_over_lab_idx(effect_idx,lab_idx[0])\n",
    "\n",
    "print('cause idx')\n",
    "print(cause_idx)\n",
    "\n",
    "print('effect idx')\n",
    "print(effect_idx)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__class__\n",
      "__delattr__\n",
      "__dict__\n",
      "__dir__\n",
      "__doc__\n",
      "__eq__\n",
      "__format__\n",
      "__ge__\n",
      "__getattribute__\n",
      "__gt__\n",
      "__hash__\n",
      "__init__\n",
      "__init_subclass__\n",
      "__le__\n",
      "__lt__\n",
      "__module__\n",
      "__ne__\n",
      "__new__\n",
      "__reduce__\n",
      "__reduce_ex__\n",
      "__repr__\n",
      "__setattr__\n",
      "__sizeof__\n",
      "__str__\n",
      "__subclasshook__\n",
      "__weakref__\n",
      "adj_mat\n",
      "all_vi\n",
      "class_varname\n",
      "dag\n",
      "feature_varnames\n",
      "label_features\n",
      "label_y\n",
      "labels\n",
      "merge_dat\n",
      "test_dataset\n",
      "test_features\n",
      "test_y\n",
      "train_label_dataset\n",
      "train_unlabel_dataset\n",
      "unlabel_features\n",
      "unlabel_y\n",
      "val_dataset\n",
      "val_features\n",
      "val_y\n",
      "vertex_dict\n",
      "pausing here\n",
      "pausing here\n",
      "pausing here\n",
      "cause idx\n",
      "[]\n",
      "effect idx\n",
      "[1, 2]\n",
      "spouse idx\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#/media/krillman/240GB_DATA/codes2/SSL_GCM/data/dataset_real_sachs_mek_log/saved_models/d_n_real_sachs_mek_log_s_i_0_dataset_class.pickle\n",
    "\n",
    "\n",
    "pkl_n='/media/krillman/240GB_DATA/codes2/SSL_GCM/data/dataset_real_sachs_raf_log/saved_models/d_n_real_sachs_raf_log_s_i_0_dataset_class.pickle'\n",
    "\n",
    "#raf \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(pkl_n, 'rb') as f:\n",
    "    dsc = pickle.load(f)\n",
    "    \n",
    "    \n",
    "    for d in dir(dsc):\n",
    "        print(d)\n",
    "    \n",
    "    \n",
    "dsc_generators=OrderedDict() #ordered dict of the generators\n",
    "dsc.label_var=dsc.class_varname\n",
    "label_name = dsc.label_var\n",
    "\n",
    "order_to_train=dsc.dag.topological_sorting()\n",
    "\n",
    "\n",
    "ordered_keys=[dsc.labels[v] for v in order_to_train]\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "dsc_generators=OrderedDict() #ordered dict of the generators\n",
    "label_name = dsc.class_varname\n",
    "ordered_keys=[dsc.labels[v] for v in order_to_train]\n",
    "\n",
    "\n",
    "is_lab=[k==label_name for k in ordered_keys]\n",
    "\n",
    "\n",
    "lab_transform = lambda lab: 'label' if lab else 'feature'\n",
    "feat_or_lab = [lab_transform(c) for c in is_lab]\n",
    "\n",
    "dsc.variable_types = feat_or_lab\n",
    "\n",
    "dsc.variable_types\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if type(label_name)=='list':\n",
    "    ln=label_name[0]\n",
    "    label_idx = np.where(np.array(ordered_keys) == ln)[0][0]\n",
    "else:\n",
    "    label_idx = np.where(np.array(ordered_keys) == label_name)[0][0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "unlabelled_keys = ordered_keys[:label_idx]\n",
    "labelled_key = ordered_keys[label_idx]\n",
    "conditional_keys = ordered_keys[label_idx + 1:]\n",
    "\n",
    "\n",
    "#split into parent, spouse, child\n",
    "topsort_order = np.array(dsc.variable_types)\n",
    "\n",
    "print('pausing here')\n",
    "\n",
    "lab_idx = np.where(topsort_order == 'label')[0]\n",
    "\n",
    "\n",
    "def reduce_list(in_list):\n",
    "    return (sum(in_list, []))\n",
    "\n",
    "\n",
    "def return_mb_dict(dag):\n",
    "\n",
    "    mb_dict = {}  # getting markov blanket\n",
    "    for n in dag.nodes:\n",
    "        mb_dict[n] = {}\n",
    "        # get parents\n",
    "        mb_dict[n]['parent'] = [n for n in dag.predecessors(n)]\n",
    "        # get children\n",
    "        mb_dict[n]['children'] = [n for n in dag.successors(n)]\n",
    "        # spouses\n",
    "        mb_dict[n]['spouses'] = reduce_list([[s for s in dag.predecessors(c)] for c in mb_dict[n]['children']])\n",
    "\n",
    "    return(mb_dict)\n",
    "\n",
    "\n",
    "# need to partition into spouse also\n",
    "\n",
    "networkx_dag = dsc.dag.to_networkx()  # converting to networkx object for easier\n",
    "mb_dict = return_mb_dict(networkx_dag)\n",
    "mb_label_var = mb_dict[lab_idx[0]]\n",
    "\n",
    "\n",
    "\n",
    "#convert to unique elements\n",
    "\n",
    "#then remove variables shared bw parent&spouse to just parent\n",
    "\n",
    "for k in mb_label_var.keys():\n",
    "    mb_label_var[k]=list(set(mb_label_var[k]))\n",
    "\n",
    "# ok now if any v common to spouse/children, put in effect only\n",
    "\n",
    "for v in mb_label_var['children']:\n",
    "    if v in mb_label_var['spouses']:\n",
    "        mb_label_var['spouses'].remove(v)\n",
    "\n",
    "# ok now if any v common to spouse/parent, put in parent only\n",
    "for v in mb_label_var['parent']:\n",
    "    if v in mb_label_var['spouses']:\n",
    "        mb_label_var['spouses'].remove(v)\n",
    "\n",
    "\n",
    "print('pausing here')\n",
    "# remove self from spouses\n",
    "try:\n",
    "    mb_label_var['spouses'].remove(lab_idx[0])\n",
    "except:\n",
    "    next\n",
    "finally:\n",
    "    next\n",
    "\n",
    "\n",
    "\n",
    "# partition into causal/label/effect index\n",
    "ce_dict = {'cause': list(set(mb_label_var['parent'])),\n",
    "                'spouse': list(set(mb_label_var['spouses'])),\n",
    "                'lab': lab_idx[0],\n",
    "                'effect': list(set(mb_label_var['children']))}\n",
    "\n",
    "print('pausing here')\n",
    "\n",
    "\n",
    "unlabelled_keys = ordered_keys[:label_idx]\n",
    "labelled_key = ordered_keys[label_idx]\n",
    "conditional_keys = ordered_keys[label_idx + 1:]\n",
    "\n",
    "\n",
    "cause_idx=ce_dict['cause']\n",
    "spouse_idx=ce_dict['spouse']\n",
    "\n",
    "effect_idx=ce_dict['effect']\n",
    "\n",
    "#subtract 1 for any over 18...\n",
    "\n",
    "def subtract_over_lab_idx(features,lab_idx):\n",
    "    newfeats=[]\n",
    "    for f in features:\n",
    "        if f>lab_idx:\n",
    "            f=f-1\n",
    "        newfeats.append(f)\n",
    "        \n",
    "    return(newfeats)\n",
    "\n",
    "cause_idx=subtract_over_lab_idx(cause_idx,lab_idx[0])\n",
    "effect_idx=subtract_over_lab_idx(effect_idx,lab_idx[0])\n",
    "spouse_idx=subtract_over_lab_idx(spouse_idx,lab_idx[0])\n",
    "\n",
    "print('cause idx')\n",
    "print(cause_idx)\n",
    "\n",
    "print('effect idx')\n",
    "print(effect_idx)\n",
    "\n",
    "print('spouse idx')\n",
    "print(spouse_idx)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sv_i', 'tv_i', 'sv_lab', 'tv_lab'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pkl.vertex_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'diagnosis'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsc.class_varname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_to_train=dsc.dag.topological_sorting()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature',\n",
       " 'feature',\n",
       " 'feature',\n",
       " 'feature',\n",
       " 'feature',\n",
       " 'feature',\n",
       " 'feature',\n",
       " 'feature',\n",
       " 'feature',\n",
       " 'feature',\n",
       " 'feature',\n",
       " 'feature',\n",
       " 'feature',\n",
       " 'feature',\n",
       " 'feature',\n",
       " 'feature',\n",
       " 'feature',\n",
       " 'feature',\n",
       " 'label',\n",
       " 'feature',\n",
       " 'feature',\n",
       " 'feature']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pausing here\n",
      "pausing here\n",
      "pausing here\n",
      "cause idx\n",
      "[0, 20, 14, 7]\n",
      "effect idx\n",
      "[1, 5, 8, 9, 12, 15, 16, 19]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pausing here\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([18])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pausing here\n",
      "pausing here\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 20, 14, 7]\n",
      "[1, 5, 8, 9, 12, 15, 16, 19]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 20, 14, 7]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cause_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sv_i': {0: [6, 13, 17],\n",
       "  1: [3, 5, 13, 18],\n",
       "  2: [1, 3, 4, 8, 9, 12, 13, 19],\n",
       "  3: [5, 13, 14, 17, 21],\n",
       "  4: [3, 5, 13, 14, 17, 20, 21],\n",
       "  5: [0, 6, 15, 16, 18],\n",
       "  6: [7],\n",
       "  7: [],\n",
       "  8: [0, 1, 3, 4, 5, 7, 9, 14, 16, 17, 18, 20, 21],\n",
       "  9: [4, 5, 7, 14, 18, 20, 21],\n",
       "  10: [8, 13, 16],\n",
       "  11: [1, 4, 5, 7, 8, 10, 12, 14, 17, 21],\n",
       "  12: [0, 6, 8, 15, 16, 18, 20],\n",
       "  13: [14, 17],\n",
       "  14: [7, 17],\n",
       "  15: [0, 14, 16, 18, 20],\n",
       "  16: [0, 6, 14, 18, 21],\n",
       "  17: [6, 7],\n",
       "  18: [0, 7, 14, 21],\n",
       "  19: [1, 7, 8, 20, 21],\n",
       "  20: [6, 14, 17, 18],\n",
       "  21: [0, 6, 13, 14, 17]},\n",
       " 'tv_i': {0: [0, 0, 0, 0, 0, 0, 0],\n",
       "  1: [1, 1, 1, 1],\n",
       "  2: [],\n",
       "  3: [3, 3, 3, 3],\n",
       "  4: [4, 4, 4, 4],\n",
       "  5: [5, 5, 5, 5, 5, 5],\n",
       "  6: [6, 6, 6, 6, 6, 6, 6],\n",
       "  7: [7, 7, 7, 7, 7, 7, 7, 7],\n",
       "  8: [8, 8, 8, 8, 8],\n",
       "  9: [9, 9],\n",
       "  10: [10],\n",
       "  11: [],\n",
       "  12: [12, 12],\n",
       "  13: [13, 13, 13, 13, 13, 13, 13],\n",
       "  14: [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14],\n",
       "  15: [15, 15],\n",
       "  16: [16, 16, 16, 16, 16],\n",
       "  17: [17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "  18: [18, 18, 18, 18, 18, 18, 18, 18],\n",
       "  19: [19],\n",
       "  20: [20, 20, 20, 20, 20, 20],\n",
       "  21: [21, 21, 21, 21, 21, 21, 21, 21]},\n",
       " 'sv_lab': {0: [6, 13, 17],\n",
       "  1: [3, 5, 13, 18],\n",
       "  2: [1, 3, 4, 8, 9, 12, 13, 19],\n",
       "  3: [5, 13, 14, 17, 21],\n",
       "  4: [3, 5, 13, 14, 17, 20, 21],\n",
       "  5: [0, 6, 15, 16, 18],\n",
       "  6: [7],\n",
       "  7: [],\n",
       "  8: [0, 1, 3, 4, 5, 7, 9, 14, 16, 17, 18, 20, 21],\n",
       "  9: [4, 5, 7, 14, 18, 20, 21],\n",
       "  10: [8, 13, 16],\n",
       "  11: [1, 4, 5, 7, 8, 10, 12, 14, 17, 21],\n",
       "  12: [0, 6, 8, 15, 16, 18, 20],\n",
       "  13: [14, 17],\n",
       "  14: [7, 17],\n",
       "  15: [0, 14, 16, 18, 20],\n",
       "  16: [0, 6, 14, 18, 21],\n",
       "  17: [6, 7],\n",
       "  18: [0, 7, 14, 21],\n",
       "  19: [1, 7, 8, 20, 21],\n",
       "  20: [6, 14, 17, 18],\n",
       "  21: [0, 6, 13, 14, 17]},\n",
       " 'tv_lab': {0: [0, 0, 0, 0, 0, 0, 0],\n",
       "  1: [1, 1, 1, 1],\n",
       "  2: [],\n",
       "  3: [3, 3, 3, 3],\n",
       "  4: [4, 4, 4, 4],\n",
       "  5: [5, 5, 5, 5, 5, 5],\n",
       "  6: [6, 6, 6, 6, 6, 6, 6],\n",
       "  7: [7, 7, 7, 7, 7, 7, 7, 7],\n",
       "  8: [8, 8, 8, 8, 8],\n",
       "  9: [9, 9],\n",
       "  10: [10],\n",
       "  11: [],\n",
       "  12: [12, 12],\n",
       "  13: [13, 13, 13, 13, 13, 13, 13],\n",
       "  14: [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14],\n",
       "  15: [15, 15],\n",
       "  16: [16, 16, 16, 16, 16],\n",
       "  17: [17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "  18: [18, 18, 18, 18, 18, 18, 18, 18],\n",
       "  19: [19],\n",
       "  20: [20, 20, 20, 20, 20, 20],\n",
       "  21: [21, 21, 21, 21, 21, 21, 21, 21]}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pkl.vertex_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pkl.adj_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas.core.indexes.numeric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/media/krillman/240GB_DATA/codes2/SSL_GCM/src/retrieve_real_dag.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/krillman/240GB_DATA/codes2/SSL_GCM/src/retrieve_real_dag.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#pkl_candidate=glob.glob(pkl_dn)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/krillman/240GB_DATA/codes2/SSL_GCM/src/retrieve_real_dag.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(pkl_n, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/krillman/240GB_DATA/codes2/SSL_GCM/src/retrieve_real_dag.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     data_pkl \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(f)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas.core.indexes.numeric'"
     ]
    }
   ],
   "source": [
    "#pkl_dn='{0}/d_n_{1}_s_i_{2}_*.pickle'.format(dspec.save_folder,args.d_n,s_i)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl_gcm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
